apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: template-preprocess-prod-data
  namespace: argo-workflows
spec:
  templates:
    - name: preprocess-prod-data
      inputs:
        parameters:
          - name: ecr-registry
          - name: image-tag
          - name: s3-artifact-bucket
          - name: workflow-name
      container:
        image: "{{inputs.parameters.ecr-registry}}:{{inputs.parameters.image-tag}}"
        command: [sh, -c]
        args:
          - |
            set -e

            # Download validated data from S3
            echo "Downloading validated data from S3..."
            python /app/src/utils/workflows_artifacts_handler.py \
              --bucket "{{inputs.parameters.s3-artifact-bucket}}" \
              --workflow-name "{{inputs.parameters.workflow-name}}" \
              download-dir \
              --s3-prefix "data/validated" \
              --local-dir "/workspace/data/validated" \
              --pattern "*.csv"

            echo "Running preprocessing with STRATIFIED split..."
            cd /workspace
            python /app/src/preprocess_data.py

            echo "Preprocessing complete! Uploading artifacts..."
            ls -lh artifacts/preprocessed/

            # Upload preprocessed data to S3
            python /app/src/utils/workflows_artifacts_handler.py \
              --bucket "{{inputs.parameters.s3-artifact-bucket}}" \
              --workflow-name "{{inputs.parameters.workflow-name}}" \
              upload-dir \
              --local-dir "/workspace/artifacts/preprocessed" \
              --s3-prefix "artifacts/preprocessed" \
              --pattern "*.csv"

            echo "Preprocessed data uploaded to S3"
        env:
          - name: PYTHONUNBUFFERED
            value: "1"
          - name: ARTIFACTS_DIR
            value: "/workspace/artifacts"
          - name: VALIDATED_DIR
            value: "/workspace/data/validated"
          - name: PREPROCESSED_DIR
            value: "/workspace/artifacts/preprocessed"
          - name: SPLIT_MODE
            value: "stratified"  # Use stratified split for retraining
        resources:
          requests:
            memory: "512Mi"
            cpu: "300m"
          limits:
            memory: "1Gi"
            cpu: "800m"
