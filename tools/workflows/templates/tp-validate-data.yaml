apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: template-validate-data
  namespace: argo-workflows
spec:
  templates:
    - name: validate-data
      inputs:
        parameters:
          - name: ecr-registry
          - name: image-tag
          - name: s3-artifact-bucket
          - name: workflow-name
      container:
        image: "{{inputs.parameters.ecr-registry}}:{{inputs.parameters.image-tag}}"
        imagePullPolicy: Always
        command: [sh, -c]
        args:
          - |
            set -e

            # Download raw data from S3
            echo "Downloading raw data from S3..."
            python /app/src/utils/workflows_artifacts_handler.py \
              --bucket "{{inputs.parameters.s3-artifact-bucket}}" \
              --workflow-name "{{inputs.parameters.workflow-name}}" \
              download-file \
              --s3-key "data/raw/Base.csv" \
              --local-path "/workspace/data/raw/Base.csv"

            echo "Running validation..."
            cd /workspace
            python /app/src/validate_data.py

            echo "Validation complete! Uploading artifacts..."
            ls -lh artifacts/validated/

            # Upload validated data to S3
            python /app/src/utils/workflows_artifacts_handler.py \
              --bucket "{{inputs.parameters.s3-artifact-bucket}}" \
              --workflow-name "{{inputs.parameters.workflow-name}}" \
              upload-dir \
              --local-dir "/workspace/artifacts/validated" \
              --s3-prefix "artifacts/validated" \
              --pattern "*.csv"

            echo "Validated data uploaded to S3"
        env:
          - name: PYTHONUNBUFFERED
            value: "1"
          - name: ARTIFACTS_DIR
            value: "/workspace/artifacts"
          - name: DATA_DIR_RAW
            value: "/workspace/data/raw"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
